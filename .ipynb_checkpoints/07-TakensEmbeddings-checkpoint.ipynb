{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdSlsOrB4vMm"
      },
      "source": [
        "# Takens Embeddings\n",
        "\n",
        "In this notebook, we'll explore the Takens embeddings introduced in lecture for applying TDA methods to time series data.\n",
        "\n",
        "We'll use tge package `giotto-tda` which has a Takens embedding module with a lot of nice features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U giotto-tda\n",
        "%pip install openml"
      ],
      "metadata": {
        "id": "c28m3DD-45z1",
        "outputId": "a1c3fdd0-9e6f-4172-8324-5df00a644a45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: giotto-tda in /usr/local/lib/python3.9/dist-packages (0.6.0)\n",
            "Requirement already satisfied: igraph>=0.9.8 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (0.10.4)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (1.2.2)\n",
            "Requirement already satisfied: plotly>=4.8.2 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (5.13.1)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (7.7.1)\n",
            "Requirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (1.1.1)\n",
            "Requirement already satisfied: giotto-ph>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (1.22.4)\n",
            "Requirement already satisfied: pyflagser>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (0.4.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from giotto-tda) (1.10.1)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.9/dist-packages (from igraph>=0.9.8->giotto-tda) (1.6.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5.1->giotto-tda) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5.1->giotto-tda) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5.1->giotto-tda) (3.0.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5.1->giotto-tda) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5.1->giotto-tda) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5.1->giotto-tda) (3.6.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly>=4.8.2->giotto-tda) (8.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.23.1->giotto-tda) (3.1.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (6.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (6.1.12)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (2.0.10)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.18.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (67.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (6.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.8.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (3.1.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (21.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.16.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (5.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (5.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.17.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (6.5.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->giotto-tda) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect->ipython>=4.0.0->ipywidgets>=7.5.1->giotto-tda) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (3.1.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (2.1.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (23.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (1.2.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (4.11.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.7.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (6.0.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.5.1->giotto-tda) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openml\n",
            "  Downloading openml-0.13.1.tar.gz (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.6/127.6 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from openml) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.9/dist-packages (from openml) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from openml) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from openml) (1.4.4)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.9/dist-packages (from openml) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.9/dist-packages (from openml) (1.22.4)\n",
            "Collecting minio\n",
            "  Downloading minio-7.1.14-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.2/77.2 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.9/dist-packages (from openml) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.0->openml) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil->openml) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->openml) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->openml) (1.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from minio->openml) (1.26.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from minio->openml) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->openml) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->openml) (3.4)\n",
            "Building wheels for collected packages: openml, liac-arff\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.13.1-py3-none-any.whl size=142798 sha256=6983baa84508bd40206a4c9df6dce488a399eade31953c56a843877ee4001f62\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/9a/36/e6701b6204a871ced537238ce7b5b2924a7408604bd301ad34\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=1a04f70ea16870760d5d7974f48b57c3234c6cc26708ad6432a66a032c97036d\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/82/8b/5c514221984e88c059b94e36a71d4722e590acaae04deab22e\n",
            "Successfully built openml liac-arff\n",
            "Installing collected packages: xmltodict, minio, liac-arff, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.1.14 openml-0.13.1 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hlJXHbny4vMr",
        "outputId": "ec35c19f-6e0e-4832-dfcc-40fcf8428203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import the gtda modules\n",
        "from gtda.time_series import SingleTakensEmbedding\n",
        "from gtda.homology import VietorisRipsPersistence\n",
        "from gtda.diagrams import Scaler, Filtering, PersistenceEntropy, BettiCurve, PairwiseDistance\n",
        "from gtda.graphs import KNeighborsGraph, GraphGeodesicDistance\n",
        "from gtda.pipeline import Pipeline\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "import plotly.express as px\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "# gtda plotting functions\n",
        "from gtda.plotting import plot_heatmap\n",
        "\n",
        "# Import data from openml\n",
        "import openml\n",
        "from openml.datasets.functions import get_dataset\n",
        "\n",
        "# Plotting functions\n",
        "from gtda.plotting import plot_diagram, plot_betti_surfaces\n",
        "from gtda.plotting import plot_point_cloud\n",
        "\n",
        "# MatPLotLib\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX9OtVRU4vMs"
      },
      "source": [
        "## A Simple Example\n",
        "\n",
        "We'll start with a simple signal consisting of a noisy sine curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym0pwWWT4vMt"
      },
      "outputs": [],
      "source": [
        "n_samples = 1000\n",
        "domain = np.linspace(0,2*np.pi,n_samples)\n",
        "noise_level = 0.5\n",
        "frequency = 4\n",
        "\n",
        "signal = np.array([np.sin(frequency*x) + noise_level * np.random.random() for x in domain])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdFSFBZQ4vMt"
      },
      "outputs": [],
      "source": [
        "plt.plot(domain,signal)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHuGWHVj4vMt"
      },
      "source": [
        "The *sliding window embedding* of the signal $f:[0,2\\pi] \\to \\mathbb{R}$ is defined in terms of two parameters:\n",
        "- $\\tau$ is the *delay*\n",
        "- $d$ is the *embedding dimension*\n",
        "\n",
        "The sliding window embedding is given by\n",
        "\\begin{align}\n",
        "\\mathrm{SW}_{d,\\tau}f:[0,2\\pi] &\\to \\mathbb{R}^d \\\\\n",
        "t &\\mapsto \\mathrm{SW}_{d,\\tau}f(t) = (f(t),f(t + \\tau),f(t+2\\tau),\\ldots,f(t+(d-1)\\tau))\n",
        "\\end{align}\n",
        "\n",
        "Let's start by embedding in $\\mathbb{R}^3$ (i.e. $d = 3$). We can experiment with different delays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vP8rU094vMu"
      },
      "outputs": [],
      "source": [
        "dimension = 3\n",
        "time_delay = 10\n",
        "\n",
        "embedder = SingleTakensEmbedding(parameters_type='fixed',dimension=dimension,time_delay=time_delay)\n",
        "embedded_signal = embedder.fit_transform(signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8R3_QO-4vMv"
      },
      "source": [
        "Let's take a look at the shape of the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9beFaG94vMv"
      },
      "outputs": [],
      "source": [
        "print('Shape of embedded point cloud:', embedded_signal.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr8MgPBZ4vMw"
      },
      "source": [
        "Notice that the number of points in the point cloud is `n_samples`-$(d-1)\\tau$. This is to mitigate boundary effects on the sliding window.\n",
        "\n",
        "Since we embedded in $\\mathbb{R}^3$, we can take a look at the embedded point cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-RGWDA44vMx"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "xs = embedded_signal[:,0]\n",
        "ys = embedded_signal[:,1]\n",
        "zs = embedded_signal[:,2]\n",
        "\n",
        "ax.scatter(xs, ys, zs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiRRlZ2z4vMx"
      },
      "source": [
        "It looks like a noisy ellipse, which agrees with our computation in lecture. `giotto` has some useful plotting tools which allow us to manipulate the plot to get a better view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNmc297b4vMy"
      },
      "outputs": [],
      "source": [
        "plot_point_cloud(embedded_signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSKRCfpH4vMy"
      },
      "source": [
        "We did a computation in class which showed that the embedded point cloud is at its 'roundest' when $\\omega \\cdot d \\cdot \\tau = 0 \\, (\\mathrm{mod} \\, \\pi)$, where $\\omega$ is the frequency. Since we are embedding with $d = 3$, we should get a round circle when $\\tau = \\frac{\\pi}{3\\omega}$. Let's test this out.\n",
        "\n",
        "**Note:** Since we are working with a discrete approximation of the signal, $\\tau$ is input as an integer---i.e., it's the number of indices to skip in the vector of signal sample values. This means we need to do a coordinate transformation and use the following time delay\n",
        "$$\n",
        "\\hat{\\tau} = \\tau \\cdot \\frac{\\mathrm{n}}{2\\pi} = \\frac{\\pi}{3\\omega} \\cdot \\frac{\\mathrm{n}}{2\\pi} = \\frac{\\mathrm{n}}{6 \\omega},\n",
        "$$\n",
        "where $n = $`n_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfUBPOi-4vMz"
      },
      "outputs": [],
      "source": [
        "time_delay = int(n_samples/(6*frequency))\n",
        "\n",
        "embedder = SingleTakensEmbedding(parameters_type='fixed',dimension=dimension,time_delay=time_delay)\n",
        "embedded_signal = embedder.fit_transform(signal)\n",
        "\n",
        "plot_point_cloud(embedded_signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGIK7v444vMz"
      },
      "source": [
        "Trying this for different values of $\\tau$, we see that the value above does seem to be of 'optimal roundness'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlKYOVWR4vMz"
      },
      "outputs": [],
      "source": [
        "tau = np.pi/5 # tau is a number between 0 and 2pi\n",
        "\n",
        "time_delay = int(tau*n_samples/(2*np.pi)) # coordinate transformation to discrete steps\n",
        "\n",
        "embedder = SingleTakensEmbedding(parameters_type='fixed',dimension=dimension,time_delay=time_delay)\n",
        "embedded_signal = embedder.fit_transform(signal)\n",
        "\n",
        "plot_point_cloud(embedded_signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGacd8tu4vM0"
      },
      "source": [
        "Let's switch back to $\\tau = \\frac{\\pi}{3\\omega}$. \n",
        "\n",
        "Next we observe that this circle is actually 'multiply covered'. I.e., since the signal runs through $\\omega$ full periods, the circle is run over $\\omega$ times.\n",
        "\n",
        "To see this, we can plot subsets of the embedded point cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgCm4pDF4vM0"
      },
      "outputs": [],
      "source": [
        "tau = np.pi/(3*frequency) \n",
        "time_delay = int(tau*n_samples/(2*np.pi))\n",
        "\n",
        "embedder = SingleTakensEmbedding(parameters_type='fixed',dimension=dimension,time_delay=time_delay)\n",
        "embedded_signal = embedder.fit_transform(signal)\n",
        "\n",
        "plot_start = 0*int(1000/frequency)\n",
        "plot_end = 1*int(1000/frequency)\n",
        "\n",
        "truncated_embedded_signal = embedded_signal[plot_start:plot_end,:]\n",
        "plot_point_cloud(truncated_embedded_signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAVk5krY4vM1"
      },
      "source": [
        "Projecting the point cloud to one of the coordinate axes produces a 1-dimensional signal which looks like what we started with, up to a translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVsRx2Sm4vM2"
      },
      "outputs": [],
      "source": [
        "projection_coord = 0\n",
        "projected_signal = embedded_signal[:,projection_coord]\n",
        "plt.plot(projected_signal)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOaVhiC4vM2"
      },
      "source": [
        "Recalling Takens' Theorem: the 'philosophical idea' here is that the embedded circle represents a bunch of steps in some dynamical system, which lie along an attractor. The projected 1-dimensional signal represents the output of some observation function. The sliding window embedding then reconstructs the attractor! The reconstruction is only up to topology---observe that for different choices of $\\tau$, we get different geometries, but the same topology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVxqwiE24vM2"
      },
      "source": [
        "Computing the PH of the embedded point cloud, we see that it has the (noisy) homology of a circle. The following is the syntax used for persistent homology in the `giotto` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1SmeNIf4vM3"
      },
      "outputs": [],
      "source": [
        "homology_dimensions = [1]\n",
        "VR = VietorisRipsPersistence(\n",
        "    metric='euclidean', max_edge_length=100, homology_dimensions=homology_dimensions)\n",
        "\n",
        "X_diagrams = VR.fit_transform(embedded_signal[None, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iooH7Nm4vM3"
      },
      "outputs": [],
      "source": [
        "plot_diagram(X_diagrams[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9pncCTV4vM3"
      },
      "source": [
        "As expected, the 'distinctness' of the degree-1 feature depends a lot on the parameters for the Takens embedding. We can see this by running over a few choices of $\\tau$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Z02Bm7dG4vM4"
      },
      "outputs": [],
      "source": [
        "taus = [np.pi/(10*frequency),np.pi/(5*frequency),np.pi/(3*frequency),np.pi/(2*frequency)]\n",
        "\n",
        "for tau in taus: \n",
        "    time_delay = int(tau*n_samples/(2*np.pi))\n",
        "\n",
        "    embedder = SingleTakensEmbedding(parameters_type='fixed',dimension=dimension,time_delay=time_delay)\n",
        "    embedded_signal = embedder.fit_transform(signal)\n",
        "    \n",
        "    X_diagrams = VR.fit_transform(embedded_signal[None, :, :])\n",
        "    plot_diagram(X_diagrams[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nA4GyXd4vM4"
      },
      "source": [
        "This should lead you to ask: given a signal with unknown 'ground truth' topology, how do we choose the correct $\\tau$? Furthermore, how do we choose the correct embedding dimension $d$?\n",
        "\n",
        "To my knowledge, this is still an open theoretical question in the TDA literature. The `giotto` package does have some statistical heuristics to choose 'optimal' parameters. To use this functionality, the user initializes with upper bounds on $d$ and $\\tau$, and some existing algorithms for phase space reconstruction are used to adjust them.\n",
        "\n",
        "**Note:** The initial upper bounds must satisfy $n \\geq (d-1)*\\tau$, where $n$ is the number of samples and $\\tau$ is the discrete time delay.\n",
        "\n",
        "**Heuristic:** Since the initializations give upper bounds, choosing them high (but satisfying the inequality above) seems to work best. However, choosing high upper bounds also increases compute time, so there is a trade off here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkivwSlo4vM5"
      },
      "outputs": [],
      "source": [
        "dimension = 30\n",
        "time_delay = 30\n",
        "\n",
        "embedder = SingleTakensEmbedding(parameters_type='search',dimension=dimension,time_delay=time_delay)\n",
        "embedded_signal = embedder.fit_transform(signal)\n",
        "\n",
        "print('Optimal embedding time delay based on mutual information:', embedder.time_delay_)\n",
        "print('Optimal embedding dimension based on false nearest neighbors:',embedder.dimension_)\n",
        "print('Shape of embedded point cloud:', embedded_signal.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-qbUWna4vM5"
      },
      "outputs": [],
      "source": [
        "homology_dimensions = [1]\n",
        "VR = VietorisRipsPersistence(\n",
        "    metric='euclidean', max_edge_length=100, homology_dimensions=homology_dimensions)\n",
        "\n",
        "X_diagrams = VR.fit_transform(embedded_signal[None, :, :])\n",
        "plot_diagram(X_diagrams[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCpBhiH14vM5"
      },
      "source": [
        "Let's compare the learned parameters to the optimal ones. We first convert the discrete time delay to the continuous one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaxJgxjP4vM6"
      },
      "outputs": [],
      "source": [
        "d = embedder.dimension_\n",
        "tau = embedder.time_delay_\n",
        "\n",
        "tau_continuous = tau*np.pi/n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y1LkAW04vM6"
      },
      "source": [
        "We then compute the quantity $\\omega \\cdot \\tau \\cdot d$ and divide by $\\pi$. If the parameters are optimal, then the result should be an integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDA3lwoK4vM7"
      },
      "outputs": [],
      "source": [
        "frequency*tau_continuous*d/np.pi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxAJ7IPL4vM8"
      },
      "source": [
        "**(Unofficial) Homework:** Run this experiment many times, using different frequencies and record the values that you get for $\\omega \\cdot \\tau \\cdot d$. Does the opimization algorithm tend to produce $d$ and $\\tau$ which make this product close to a multiple of $\\pi$? If the answer is \"Yes\", that's great! If the answer is \"No\", maybe there is some room for improvement in this optimization algorithm..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON5nfaaP4vM8"
      },
      "source": [
        "## Lorenz Attractor\n",
        "\n",
        "We motivated Takens' Theorem with the Lorenz system. Let's take a closer look at this using the `giotto` package. We can load in a point cloud version of the attractor as a preprocessed dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq8Qm6Kq4vM9"
      },
      "outputs": [],
      "source": [
        "point_cloud = get_dataset(42182).get_data(dataset_format='array')[0]\n",
        "plot_point_cloud(point_cloud)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hoz0_QO4vM9"
      },
      "source": [
        "We can project to one of the axes to get a time series, serving as a proxy for the values of an observation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anbtBE5i4vM9"
      },
      "outputs": [],
      "source": [
        "signal = point_cloud[:,0]\n",
        "plt.plot(signal)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XilB2WAu4vM-"
      },
      "source": [
        "The resulting time series is much more complicated than our sine curve above. Let's see if the sliding window embedding reconstructs the Lorenz attractor (topologically).\n",
        "\n",
        "**Full Disclosure:** The upper bound of 3 on the time delay in the next cell was chosen by playing with parameters for a while. So this reconstruction is not fully unsupervised..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPBbOyuw4vM-"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 20\n",
        "time_delay = 3\n",
        "embedder = SingleTakensEmbedding(parameters_type='search', dimension=embedding_dimension, time_delay=time_delay)\n",
        "embedded_signal = embedder.fit_transform(signal)\n",
        "\n",
        "print('Optimal embedding time delay based on mutual information:', embedder.time_delay_)\n",
        "print('Optimal embedding dimension based on false nearest neighbors:',embedder.dimension_)\n",
        "print('Shape of embedded point cloud:', embedded_signal.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtJqdRSO4vM-"
      },
      "source": [
        "Since we are embedding in high dimensions, we can't plot the full dimensional point cloud. We can project to a 3-dimensional subspace and plot the result. We'll use the first three principal vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29RkUg6f4vM_"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xWjQruF4vM_"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=3)\n",
        "X = pca.fit_transform(embedded_signal)\n",
        "plot_point_cloud(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m_IcKw-4vM_"
      },
      "source": [
        "Computing the persistent homology of a point cloud with ~5k points takes a while. Let's subsample the point cloud before doing the computation, for the sake of class time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C1aRtBQ4vM_"
      },
      "outputs": [],
      "source": [
        "subsample_factor = 5\n",
        "subsampled_embedded_signal = np.array([embedded_signal[subsample_factor*t,:] for t in range(int(len(embedded_signal)/subsample_factor))])\n",
        "print(len(subsampled_embedded_signal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-9WKD7U4vNA"
      },
      "outputs": [],
      "source": [
        "homology_dimensions = [1]\n",
        "VR = VietorisRipsPersistence(\n",
        "    metric='euclidean', max_edge_length=100, homology_dimensions=homology_dimensions)\n",
        "\n",
        "X_diagrams = VR.fit_transform(subsampled_embedded_signal[None, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zsUJvfN4vNA"
      },
      "outputs": [],
      "source": [
        "plot_diagram(X_diagrams[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0DS3AhC4vNA"
      },
      "source": [
        "## Gravitational Waves\n",
        "\n",
        "Now let's use Takens embedding in a more realistic data analysis pipeline. This part of the notebook is adapted from an example provided in the `giotto-tda` documentation --- see [GitHub](https://github.com/giotto-ai/giotto-tda/blob/master/examples/gravitational_waves_detection.ipynb). They have plenty of other cool examples to try freely available on their GitHub, I highly recommend checking it out!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1W3nc9R4vNA"
      },
      "source": [
        "This experiment attepts to detect gravitational waves from noisy data using Takens embeddings. It is based on the article [Detection of gravitational waves using topological data analysis and convolutional neural network: An improved approach](https://arxiv.org/abs/1910.08245) by Christopher Bresten and Jae-Hun Jung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx5LxNrv4vNB"
      },
      "source": [
        "In the article, the authors create a synthetic training set as follows: \n",
        "\n",
        "* Generate gravitational wave signals that correspond to non-spinning binary black hole mergers\n",
        "* Generate a noisy time series and embed a gravitational wave signal with probability 0.5 at a random time.\n",
        "\n",
        "The result is a set of time series of the form\n",
        "\n",
        "$$ s = g + \\epsilon \\frac{1}{R}\\xi $$\n",
        "\n",
        "where $g$ is a gravitational wave signal from the reference set, $\\xi$ is Gaussian noise, $\\epsilon=10^{-19}$ scales the noise amplitude to the signal, and $R \\in (0.075, 0.65)$ is a parameter that controls the signal-to-noise-ratio (SNR)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhU6RjBN4vNB"
      },
      "source": [
        "## Constant signal-to-noise ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPQ-Fid4vNB"
      },
      "source": [
        "As a warmup, let's generate some noisy signals with a constant SNR of 17.98. As shown in Table 1 of the article, this corresponds to an $R$ value of 0.65. We'll run the experiment on a small-ish dataset for the sake of finishing within class time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YJGRUbA4vNB"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def make_gravitational_waves(\n",
        "    path_to_data: Path,\n",
        "    n_signals: int = 30,\n",
        "    downsample_factor: int = 2,\n",
        "    r_min: float = 0.075,\n",
        "    r_max: float = 0.65,\n",
        "    n_snr_values: int = 10,\n",
        "        ):\n",
        "    def padrand(V, n, kr):\n",
        "        cut = np.random.randint(n)\n",
        "        rand1 = np.random.randn(cut)\n",
        "        rand2 = np.random.randn(n - cut)\n",
        "        out = np.concatenate((rand1 * kr, V, rand2 * kr))\n",
        "        return out\n",
        "\n",
        "    Rcoef = np.linspace(r_min, r_max, n_snr_values)\n",
        "    Npad = 500  # number of padding points on either side of the vector\n",
        "    gw = np.load(path_to_data / \"gravitational_wave_signals.npy\")\n",
        "    Norig = len(gw[\"data\"][0])\n",
        "    Ndat = len(gw[\"signal_present\"])\n",
        "    N = int(Norig / downsample_factor)\n",
        "\n",
        "    ncoeff = []\n",
        "    Rcoeflist = []\n",
        "\n",
        "    for j in range(n_signals):\n",
        "        ncoeff.append(10 ** (-19) * (1 / Rcoef[j % n_snr_values]))\n",
        "        Rcoeflist.append(Rcoef[j % n_snr_values])\n",
        "\n",
        "    noisy_signals = []\n",
        "    gw_signals = []\n",
        "    k = 0\n",
        "    labels = np.zeros(n_signals)\n",
        "\n",
        "    for j in range(n_signals):\n",
        "        signal = gw[\"data\"][j % Ndat][range(0, Norig, downsample_factor)]\n",
        "        sigp = int((np.random.randn() < 0))\n",
        "        noise = ncoeff[j] * np.random.randn(N)\n",
        "        labels[j] = sigp\n",
        "        if sigp == 1:\n",
        "            rawsig = padrand(signal + noise, Npad, ncoeff[j])\n",
        "            if k == 0:\n",
        "                k = 1\n",
        "        else:\n",
        "            rawsig = padrand(noise, Npad, ncoeff[j])\n",
        "        noisy_signals.append(rawsig.copy())\n",
        "        gw_signals.append(signal)\n",
        "\n",
        "    return noisy_signals, gw_signals, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt2fWoIN4vNC"
      },
      "outputs": [],
      "source": [
        "R = 0.65\n",
        "n_signals = 100\n",
        "DATA = Path(\"./data\")\n",
        "\n",
        "noisy_signals, gw_signals, labels = make_gravitational_waves(\n",
        "    path_to_data=DATA, n_signals=n_signals, r_min=R, r_max=R, n_snr_values=1\n",
        ")\n",
        "\n",
        "print(f\"Number of noisy signals: {len(noisy_signals)}\")\n",
        "print(f\"Number of timesteps per series: {len(noisy_signals[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWF1jNDg4vNC"
      },
      "source": [
        "The code below visualizes the data we are working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N65BMWeU4vNC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# get the index corresponding to the first pure noise time series\n",
        "background_idx = np.argmin(labels)\n",
        "# get the index corresponding to the first noise + gravitational wave time series\n",
        "signal_idx = np.argmax(labels)\n",
        "\n",
        "ts_noise = noisy_signals[background_idx]\n",
        "ts_background = noisy_signals[signal_idx]\n",
        "ts_signal = gw_signals[signal_idx]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=list(range(len(ts_noise))), y=ts_noise, mode=\"lines\", name=\"noise\"),\n",
        "    row=1,\n",
        "    col=1,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(range(len(ts_background))),\n",
        "        y=ts_background,\n",
        "        mode=\"lines\",\n",
        "        name=\"background\",\n",
        "    ),\n",
        "    row=1,\n",
        "    col=2,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=list(range(len(ts_signal))), y=ts_signal, mode=\"lines\", name=\"signal\"),\n",
        "    row=1,\n",
        "    col=2,\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXdi9p_j4vNC"
      },
      "source": [
        "Let's use the Takens embedding to turn each time series in our dataset into a point cloud. Note that there is an extra parameter here called 'stride'. This has the effect of subsampling the time series (by a factor of `stride`). This will be useful to improve computation time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qndoUxT04vNC"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 30\n",
        "embedding_time_delay = 30\n",
        "stride = 5\n",
        "\n",
        "embedder = SingleTakensEmbedding(\n",
        "    parameters_type=\"search\", n_jobs=6, time_delay=embedding_time_delay, dimension=embedding_dimension, stride=stride\n",
        ")\n",
        "\n",
        "y_gw_embedded = embedder.fit_transform(gw_signals[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW-Ii8S14vND"
      },
      "source": [
        "As we did above, we can project to a 3-dimensional PCA basis to visualize the embedded data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssxfihk34vND"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from gtda.plotting import plot_point_cloud\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "y_gw_embedded_pca = pca.fit_transform(y_gw_embedded)\n",
        "\n",
        "plot_point_cloud(y_gw_embedded_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIo2ZLqS4vND"
      },
      "source": [
        "The code below visualizes an embedding of pure noise data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf-WySN94vND"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 30\n",
        "embedding_time_delay = 30\n",
        "stride = 5\n",
        "\n",
        "embedder = SingleTakensEmbedding(\n",
        "    parameters_type=\"search\", n_jobs=6, time_delay=embedding_time_delay, dimension=embedding_dimension, stride=stride\n",
        ")\n",
        "\n",
        "y_noise_embedded = embedder.fit_transform(noisy_signals[background_idx])\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "y_noise_embedded_pca = pca.fit_transform(y_noise_embedded)\n",
        "\n",
        "plot_point_cloud(y_noise_embedded_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF1uSaiG4vNE"
      },
      "source": [
        "### Define the topological feature generation pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebYuv9T44vNE"
      },
      "source": [
        "The code below creates a Takens embedding for each time series in our dataset, normalizes the embedded point clouds, computes degree-0 and degree-1 persistent homology and then collects some summary statistics---in particular, the [Persistence Entropy](https://arxiv.org/pdf/1902.06467.pdf). Each time series ends up being represented by a two-dimensional vector!\n",
        "\n",
        "The hyperparameters below are taken from the original example on the `giotto` GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3h56bcp4vNF"
      },
      "outputs": [],
      "source": [
        "from gtda.diagrams import PersistenceEntropy, Scaler\n",
        "from gtda.homology import VietorisRipsPersistence\n",
        "from gtda.metaestimators import CollectionTransformer\n",
        "from gtda.pipeline import Pipeline\n",
        "from gtda.time_series import TakensEmbedding\n",
        "\n",
        "embedding_dimension = 200\n",
        "embedding_time_delay = 10\n",
        "stride = 10\n",
        "\n",
        "embedder = TakensEmbedding(time_delay=embedding_time_delay,\n",
        "                           dimension=embedding_dimension,\n",
        "                           stride=stride)\n",
        "\n",
        "batch_pca = CollectionTransformer(PCA(n_components=3))\n",
        "\n",
        "persistence = VietorisRipsPersistence(homology_dimensions=[0, 1])\n",
        "\n",
        "scaling = Scaler()\n",
        "\n",
        "entropy = PersistenceEntropy(normalize=True, nan_fill_value=-10)\n",
        "\n",
        "\n",
        "steps = [(\"embedder\", embedder),\n",
        "         (\"pca\", batch_pca),\n",
        "         (\"persistence\", persistence),\n",
        "         (\"scaling\", scaling),\n",
        "         (\"entropy\", entropy)]\n",
        "topological_transfomer = Pipeline(steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YVvlaev4vNG"
      },
      "outputs": [],
      "source": [
        "features = topological_transfomer.fit_transform(noisy_signals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFxh8e6m4vNG"
      },
      "source": [
        "### Train and evaluate a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j96XstyH4vNH"
      },
      "source": [
        "Now let's see how well our features can be classified via Support Vector Machines. See we have a small dataset, let's do a number of train/test splits. This can be accomplished via the `cross-validate` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6AholYd4vNH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hqjC9pe4vNH"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "modelSVM = SVC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKiqL0vV4vNH"
      },
      "outputs": [],
      "source": [
        "cv_results = cross_validate(modelSVM,features,labels,cv = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJDLRfHa4vNH"
      },
      "outputs": [],
      "source": [
        "np.mean(cv_results['test_score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEgmf24X4vNI"
      },
      "source": [
        "Not bad for such a simple model!\n",
        "\n",
        "**Challenge:** Create a better model using some other vectorization scheme for persistence diagrams, different Takens Embedding parameters and/or a different classification model."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}